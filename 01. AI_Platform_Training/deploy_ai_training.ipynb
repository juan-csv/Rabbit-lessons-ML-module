{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 80)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2592      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,681\n",
      "Trainable params: 3,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "Prepare dataset ...\n",
      "Train on 12857 samples, validate on 1580 samples\n",
      "Epoch 1/10\n",
      "12857/12857 [==============================] - 1s 82us/sample - loss: 0.6749 - acc: 0.5766 - val_loss: 0.6375 - val_acc: 0.6316\n",
      "Epoch 2/10\n",
      "12857/12857 [==============================] - 0s 22us/sample - loss: 0.6365 - acc: 0.6336 - val_loss: 0.5885 - val_acc: 0.7108\n",
      "Epoch 3/10\n",
      "12857/12857 [==============================] - 0s 20us/sample - loss: 0.5989 - acc: 0.6801 - val_loss: 0.5568 - val_acc: 0.7196\n",
      "Epoch 4/10\n",
      "12857/12857 [==============================] - 0s 20us/sample - loss: 0.5814 - acc: 0.6915 - val_loss: 0.5461 - val_acc: 0.7196\n",
      "Epoch 5/10\n",
      "12857/12857 [==============================] - 0s 21us/sample - loss: 0.5733 - acc: 0.7009 - val_loss: 0.5387 - val_acc: 0.7247\n",
      "Epoch 6/10\n",
      "12857/12857 [==============================] - 0s 22us/sample - loss: 0.5660 - acc: 0.7069 - val_loss: 0.5324 - val_acc: 0.7209\n",
      "Epoch 7/10\n",
      "12857/12857 [==============================] - 0s 22us/sample - loss: 0.5617 - acc: 0.7117 - val_loss: 0.5297 - val_acc: 0.7241\n",
      "Epoch 8/10\n",
      "12857/12857 [==============================] - 0s 21us/sample - loss: 0.5585 - acc: 0.7148 - val_loss: 0.5260 - val_acc: 0.7316\n",
      "Epoch 9/10\n",
      "12857/12857 [==============================] - 0s 22us/sample - loss: 0.5538 - acc: 0.7198 - val_loss: 0.5226 - val_acc: 0.7323\n",
      "Epoch 10/10\n",
      "12857/12857 [==============================] - 0s 20us/sample - loss: 0.5482 - acc: 0.7198 - val_loss: 0.5189 - val_acc: 0.7304\n",
      "Exported trained model to gs://datasets-rabbit/models/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "2021-05-05 20:19:36.131096: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
      "2021-05-05 20:19:36.131513: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556f8c692870 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-05-05 20:19:36.131549: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-05-05 20:19:36.132117: I tensorflow/core/common_runtime/process_util.cc:136] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2021-05-05 20:19:40.706430: I tensorflow/core/common_runtime/process_util.cc:136] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2021-05-05 20:19:41.048035: W tensorflow/python/util/util.cc:299] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "BUCKET=datasets-rabbit\n",
    "OUTDIR=gs://${BUCKET}/models/\n",
    "JOBID=rabbit_$(date -u +%y%m%d_%H%M%S)\n",
    "TFVERSION=2.1\n",
    "PYTHONVERSION=3.7\n",
    "SERVICE_ACCOUNT=key-rabbit-ml@interno-rabbit-academy-qa.iam.gserviceaccount.com\n",
    "\n",
    "\n",
    "gcloud ai-platform local train \\\n",
    "    --module-name=trainer.task \\\n",
    "    --package-path=trainer \\\n",
    "    --\\\n",
    "    --BUCKET=${BUCKET} \\\n",
    "    --FILE_TRAIN=train_census.csv \\\n",
    "    --FILE_VAL=validation_census.csv \\\n",
    "    --OUTPUT_DIR=${OUTDIR} \\\n",
    "    --DENSE_UNITS=32 \\\n",
    "    --EPOCHS=10 \\\n",
    "    --BATCH_SIZE=256 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: rabbit_210505_202344\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [rabbit_210505_202344] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe rabbit_210505_202344\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs rabbit_210505_202344\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "BUCKET=datasets-rabbit\n",
    "OUTDIR=gs://${BUCKET}/models/\n",
    "JOBID=rabbit_$(date -u +%y%m%d_%H%M%S)\n",
    "TFVERSION=2.1\n",
    "PYTHONVERSION=3.7\n",
    "SERVICE_ACCOUNT=key-rabbit-ml@interno-rabbit-academy-qa.iam.gserviceaccount.com\n",
    "\n",
    "gcloud ai-platform jobs submit training ${JOBID} \\\n",
    "    --region=us-central1 \\\n",
    "    --module-name=trainer.task \\\n",
    "    --package-path=trainer \\\n",
    "    --job-dir=${OUTDIR} \\\n",
    "    --staging-bucket=gs://${BUCKET} \\\n",
    "    --master-machine-type=n1-standard-8 \\\n",
    "    --scale-tier=CUSTOM \\\n",
    "    --runtime-version=${TFVERSION} \\\n",
    "    --python-version=${PYTHONVERSION} \\\n",
    "    --service-account=${SERVICE_ACCOUNT} \\\n",
    "    -- \\\n",
    "    --BUCKET=${BUCKET} \\\n",
    "    --FILE_TRAIN=train_census.csv \\\n",
    "    --FILE_VAL=validation_census.csv \\\n",
    "    --OUTPUT_DIR=${OUTDIR} \\\n",
    "    --DENSE_UNITS=32 \\\n",
    "    --EPOCHS=10 \\\n",
    "    --BATCH_SIZE=256 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud ai-platform jobs stream-logs rabbit_210505_195159"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run script local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 80)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2592      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,681\n",
      "Trainable params: 3,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 0.6964 - accuracy: 0.5449 - val_loss: 0.6489 - val_accuracy: 0.6038\n",
      "Epoch 2/10\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6516 - accuracy: 0.6052 - val_loss: 0.6020 - val_accuracy: 0.6873\n",
      "Epoch 3/10\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6231 - accuracy: 0.6525 - val_loss: 0.5615 - val_accuracy: 0.7146\n",
      "Epoch 4/10\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.5897 - accuracy: 0.6910 - val_loss: 0.5479 - val_accuracy: 0.7209\n",
      "Epoch 5/10\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7010 - val_loss: 0.5364 - val_accuracy: 0.7209\n",
      "Epoch 6/10\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.7088 - val_loss: 0.5332 - val_accuracy: 0.7241\n",
      "Epoch 7/10\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.5650 - accuracy: 0.7095 - val_loss: 0.5281 - val_accuracy: 0.7253\n",
      "Epoch 8/10\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7190 - val_loss: 0.5245 - val_accuracy: 0.7285\n",
      "Epoch 9/10\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.5562 - accuracy: 0.7129 - val_loss: 0.5215 - val_accuracy: 0.7285\n",
      "Epoch 10/10\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.5481 - accuracy: 0.7226 - val_loss: 0.5200 - val_accuracy: 0.7297\n",
      "Exported trained model to models\n",
      "2021-05-05 11:50:22.856455: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-05-05 11:50:22.856648: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-05-05 11:50:32.985846: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-05-05 11:50:34.862893: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "BUCKET=datasets-rabbit\n",
    "python trainer/task.py \\\n",
    "    --BUCKET=${BUCKET} \\\n",
    "    --FILE_TRAIN=train_census.csv \\\n",
    "    --FILE_VAL=validation_census.csv \\\n",
    "    --OUTPUT_DIR=models \\\n",
    "    --DENSE_UNITS=32 \\\n",
    "    --EPOCHS=10 \\\n",
    "    --BATCH_SIZE=256 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m68",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m68"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
